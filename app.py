import streamlit as st
import pandas as pd
from PIL import Image
import wikipedia
import difflib

# ğŸ› ï¸ é é¢è¨­å®š
st.set_page_config(page_title="å¥ä¿è—¥å“æŸ¥è©¢ä»‹é¢", layout="centered")

# ğŸ·ï¸ æ¨™é¡Œ
st.title("2024 å¥ä¿ç”³å ±è—¥å“æ•¸é‡æŸ¥è©¢ä»‹é¢ï¼ˆé€²åŒ–ç‰ˆï¼‰")

# ğŸ“„ è®€å– CSV æª”æ¡ˆ
df = pd.read_csv(
    "merged_pay2024.csv",
    encoding="utf-8",
    usecols=["è—¥å“ä»£ç¢¼", "è—¥å“åç¨±", "æ•¸é‡", "è—¥å•†"],
    low_memory=False
)

# ğŸ—‚ï¸ åˆ¥åå­—å…¸ï¼ˆä¿—ç¨± â†” å­¸åï¼‰
alias_map = {
    "acetylsalicylic acid": ["aspirin", "é˜¿å¸åŒ¹æ—", "ä¹™é†¯æ°´æ¥Šé…¸"],
    "acetaminophen": ["paracetamol", "tylenol", "æ’²ç†±æ¯ç—›"],
    "ibuprofen": ["å¸ƒæ´›èŠ¬", "advil", "motrin"],
    "terlipressin": ["ç‰¹åˆ©åŠ å£“ç´ ", "TERLIPRESSIN", "ç‰¹åˆ©æ™®é›·è¾›"],
}

# å»ºç«‹å®Œæ•´è—¥å“æ¸…å–®ï¼ˆæ¨™æº–å + åˆ¥åï¼‰
drug_list = list(alias_map.keys()) + [a for aliases in alias_map.values() for a in aliases]

# ğŸ” æ¨™æº–åŒ–æŸ¥è©¢
def normalize_query(query, alias_map):
    q = query.lower().strip()
    for standard, aliases in alias_map.items():
        if q == standard.lower() or q in [a.lower() for a in aliases]:
            return standard, None
    match = difflib.get_close_matches(q, drug_list, n=1, cutoff=0.7)
    if match:
        return match[0], q
    return q, None

# ğŸ” æŸ¥è©¢è¼¸å…¥
keyword = st.text_input("è«‹è¼¸å…¥ä¸»æˆåˆ†æˆ–ä¿—ç¨±")

if keyword:
    normalized, original = normalize_query(keyword, alias_map)

    if original and normalized != original:
        st.info(f"æ‚¨æ˜¯ä¸æ˜¯è¦æŸ¥è©¢ï¼š**{normalized}**ï¼Ÿï¼ˆåŸå§‹è¼¸å…¥ï¼š{original}ï¼‰")
    else:
        st.write(f"ğŸ” æ¨™æº–åŒ–æŸ¥è©¢ï¼š**{normalized}**")

    # ğŸ“˜ Wikipedia æŸ¥è©¢ç”¨é€”
    wikipedia.set_lang("zh")
    try:
        summary = wikipedia.summary(normalized, sentences=2)
        st.write("ğŸ“˜ ä¸»æˆåˆ†ç”¨é€”ï¼ˆä¾†è‡ª Wikipediaï¼‰ï¼š")
        st.info(summary)
        page = wikipedia.page(normalized)
        st.markdown(f"[ğŸ”— æŸ¥çœ‹å®Œæ•´ Wikipedia é é¢]({page.url})")
    except wikipedia.exceptions.PageError:
        st.warning("æ‰¾ä¸åˆ° Wikipedia é é¢ï¼Œå¯èƒ½éœ€è¦æ›´ç²¾ç¢ºçš„ä¸»æˆåˆ†åç¨±ã€‚")
    except wikipedia.exceptions.DisambiguationError as e:
        st.warning(f"ä¸»æˆåˆ†åç¨±éæ–¼æ¨¡ç³Šï¼Œè«‹é¸æ“‡æ›´å…·é«”çš„è©ï¼Œä¾‹å¦‚ï¼š{e.options
