import streamlit as st
import pandas as pd
from PIL import Image
import wikipedia
import difflib

# ğŸ› ï¸ é é¢è¨­å®š
st.set_page_config(page_title="å¥ä¿è—¥å“æŸ¥è©¢ä»‹é¢", layout="centered")
st.title("2024 å¥ä¿ç”³å ±è—¥å“æ•¸é‡æŸ¥è©¢ä»‹é¢ï¼ˆé€²åŒ–ç‰ˆï¼‰")

# ğŸ“„ è®€å– CSV æª”æ¡ˆï¼ˆåŒ…å«æ”¯ä»˜åƒ¹æ¬„ä½ï¼‰
df = pd.read_csv(
    "merged_pay2024.csv",
    encoding="utf-8",
    usecols=["è—¥å“ä»£ç¢¼", "è—¥å“åç¨±", "æ•¸é‡", "è—¥å•†", "æ”¯ä»˜åƒ¹"],
    low_memory=False
)

# ğŸ—‚ï¸ åˆ¥åå­—å…¸ï¼ˆä¿—ç¨± â†” å­¸åï¼‰
alias_map = {
    "acetylsalicylic acid": ["aspirin", "é˜¿å¸åŒ¹æ—", "ä¹™é†¯æ°´æ¥Šé…¸"],
    "acetaminophen": ["paracetamol", "tylenol", "æ’²ç†±æ¯ç—›"],
    "ibuprofen": ["å¸ƒæ´›èŠ¬", "advil", "motrin"],
    "terlipressin": ["ç‰¹åˆ©åŠ å£“ç´ ", "TERLIPRESSIN", "ç‰¹åˆ©æ™®é›·è¾›"],
}

drug_list = list(alias_map.keys()) + [a for aliases in alias_map.values() for a in aliases]

# ğŸ” æ¨™æº–åŒ–æŸ¥è©¢
def normalize_query(query, alias_map):
    q = query.lower().strip()
    for standard, aliases in alias_map.items():
        if q == standard.lower() or q in [a.lower() for a in aliases]:
            return standard, None
    match = difflib.get_close_matches(q, drug_list, n=1, cutoff=0.7)
    if match:
        return match[0], q
    return q, None

# ğŸ” æŸ¥è©¢è¼¸å…¥
keyword = st.text_input("è«‹è¼¸å…¥ä¸»æˆåˆ†æˆ–ä¿—ç¨±")

if keyword:
    normalized, original = normalize_query(keyword, alias_map)

    if original and normalized != original:
        st.info(f"æ‚¨æ˜¯ä¸æ˜¯è¦æŸ¥è©¢ï¼š**{normalized}**ï¼Ÿï¼ˆåŸå§‹è¼¸å…¥ï¼š{original}ï¼‰")
    else:
        st.write(f"ğŸ” æ¨™æº–åŒ–æŸ¥è©¢ï¼š**{normalized}**")

    # ğŸ“˜ Wikipedia æŸ¥è©¢ç”¨é€”
    wikipedia.set_lang("zh")
    try:
        summary = wikipedia.summary(normalized, sentences=2)
        st.write("ğŸ“˜ ä¸»æˆåˆ†ç”¨é€”ï¼ˆä¾†è‡ª Wikipediaï¼‰ï¼š")
        st.info(summary)
        page = wikipedia.page(normalized)
        st.markdown(f"[ğŸ”— æŸ¥çœ‹å®Œæ•´ Wikipedia é é¢]({page.url})")
    except wikipedia.exceptions.PageError:
        st.warning("æ‰¾ä¸åˆ° Wikipedia é é¢ï¼Œå¯èƒ½éœ€è¦æ›´ç²¾ç¢ºçš„ä¸»æˆåˆ†åç¨±ã€‚")
    except wikipedia.exceptions.DisambiguationError as e:
        options = ", ".join(e.options[:3])
        st.warning(f"ä¸»æˆåˆ†åç¨±éæ–¼æ¨¡ç³Šï¼Œè«‹é¸æ“‡æ›´å…·é«”çš„è©ï¼Œä¾‹å¦‚ï¼š{options}")

    # ğŸ“Š æŸ¥è©¢çµæœ
    result = df[df["è—¥å“åç¨±"].str.contains(normalized, case=False, na=False)].copy()

    if result.empty:
        st.warning("æŸ¥ç„¡ç¬¦åˆè—¥å“")
    else:
        # å¼·åˆ¶è½‰æ›æ”¯ä»˜åƒ¹ç‚ºæ•¸å€¼å‹æ…‹
        result["ä½¿ç”¨é‡"] = result["æ•¸é‡"].round(1)
        result["æ”¯ä»˜åƒ¹"] = pd.to_numeric(result["æ”¯ä»˜åƒ¹"], errors="coerce").round(1)

        # ğŸ”´ é€ç­†æ˜ç´°è¡¨æ ¼ï¼ˆåŠ ä¸Šæ”¯ä»˜åƒ¹èˆ‡ç¸½é‡‘é¡ï¼‰
        detail = result[["è—¥å“ä»£ç¢¼", "è—¥å“åç¨±", "è—¥å•†", "ä½¿ç”¨é‡", "æ”¯ä»˜åƒ¹"]].copy()
        detail.insert(0, "åºè™Ÿ", range(1, len(detail) + 1))
        detail["ç¸½é‡‘é¡"] = (detail["ä½¿ç”¨é‡"] * detail["æ”¯ä»˜åƒ¹"]).round(1)
        detail = detail.reset_index(drop=True)

        st.write("ğŸ”´ æŸ¥è©¢çµæœï¼ˆé€ç­†æ˜ç´°ï¼‰ï¼š")
        st.dataframe(detail, hide_index=True)
        st.caption(f"å…± {len(detail)} ç­†")

        # âœ… è—¥å“åŒåç¨±ç´¯è¨ˆè¡¨æ ¼ï¼ˆç§»é™¤æ”¯ä»˜åƒ¹ï¼Œå¢åŠ ç™¾åˆ†æ¯”ï¼‰
        summary = result.groupby("è—¥å“åç¨±", as_index=False).agg(
            {"ä½¿ç”¨é‡": "sum", "æ”¯ä»˜åƒ¹": "mean"}
        )
        summary.rename(columns={"ä½¿ç”¨é‡": "ç´¯è¨ˆç¸½é‡"}, inplace=True)
        summary["ç´¯è¨ˆç¸½é‡"] = summary["ç´¯è¨ˆç¸½é‡"].round(1)
        summary["ç´¯è¨ˆç¸½é‡‘é¡"] = (summary["ç´¯è¨ˆç¸½é‡"] * summary["æ”¯ä»˜åƒ¹"]).round(1)

        total_amount = summary["ç´¯è¨ˆç¸½é‡‘é¡"].sum()
        summary["ç™¾åˆ†æ¯”"] = (summary["ç´¯è¨ˆç¸½é‡‘é¡"] / total_amount * 100).round(1)

        summary = summary[["è—¥å“åç¨±", "ç´¯è¨ˆç¸½é‡", "ç´¯è¨ˆç¸½é‡‘é¡", "ç™¾åˆ†æ¯”"]].copy()
        summary.insert(0, "åºè™Ÿ", range(1, len(summary) + 1))
        summary = summary.reset_index(drop=True)

        st.write("âœ… æŸ¥è©¢çµæœï¼ˆè—¥å“åŒåç¨±ç´¯è¨ˆï¼‰ï¼š")
        st.dataframe(summary, hide_index=True)
        st.caption(f"å…± {len(summary)} ç­†")

        # ğŸ¢ è—¥å•†ç´¯è¨ˆç¸½é‡‘é¡è¡¨æ ¼ï¼ˆåªé¡¯ç¤ºè—¥å•†ã€ç¸½é‡‘é¡ã€ç™¾åˆ†æ¯”ï¼‰
        company_summary = result.groupby("è—¥å•†", as_index=False).agg(
            {"ä½¿ç”¨é‡": "sum", "æ”¯ä»˜åƒ¹": "mean"}
        )
        company_summary["ç´¯è¨ˆç¸½é‡‘é¡"] = (company_summary["ä½¿ç”¨é‡"] * company_summary["æ”¯ä»˜åƒ¹"]).round(1)

        total_company_amount = company_summary["ç´¯è¨ˆç¸½é‡‘é¡"].sum()
        company_summary["ç™¾åˆ†æ¯”"] = (company_summary["ç´¯è¨ˆç¸½é‡‘é¡"] / total_company_amount * 100).round(1)

        company_summary = company_summary[["è—¥å•†", "ç´¯è¨ˆç¸½é‡‘é¡", "ç™¾åˆ†æ¯”"]].copy()
        company_summary.insert(0, "åºè™Ÿ", range(1, len(company_summary) + 1))
        company_summary = company_summary.reset_index(drop=True)

        st.write("ğŸ¢ æŸ¥è©¢çµæœï¼ˆè—¥å•†ç´¯è¨ˆç¸½é‡‘é¡ï¼‰ï¼š")
        st.dataframe(company_summary, hide_index=True)
        st.caption(f"å…± {len(company_summary)} å®¶è—¥å•†")

        # â¬‡ï¸ æä¾›ä¸‹è¼‰åŠŸèƒ½ï¼ˆä¸‹è¼‰è—¥å“ç´¯è¨ˆçµæœï¼‰
        csv = summary.to_csv(index=False, encoding="utf-8-sig")
        file_name = f"{normalized}_ç´¯è¨ˆæŸ¥è©¢çµæœ.csv"
        st.download_button(
            label="ä¸‹è¼‰ç´¯è¨ˆæŸ¥è©¢çµæœ CSV",
            data=csv,
            file_name=file_name,
            mime="text/csv",
        )
else:
    st.info("è«‹è¼¸å…¥ä¸»æˆåˆ†ä»¥é€²è¡ŒæŸ¥è©¢")

# ğŸ–¼ï¸ éƒµç¥¨åœ–ç‰‡
stamp = Image.open("white6_stamp.jpg")
st.image(stamp, caption="ç™½å…­èˆªç©º å£¹åœ“ éƒµç¥¨", width=90)
